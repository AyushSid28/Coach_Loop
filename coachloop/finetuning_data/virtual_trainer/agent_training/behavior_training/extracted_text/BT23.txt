The Systematic Design of Instruction 
 
Walter Dick, Florida State University 
Lou Carey, University of South Florida 
James O. Carey, University of South Florida 
 
Contents 
 
Preface xvii 
 
To the Instructor xxi 
 
Chapter 1 
Introduction to Instructional Design 2 
 
The Dick and Carey Systems Approach Model for Designing Instruction 2 
 
Components of the Systems Approach Model 6 
Assess Needs to Identify Goal(s) 6 
Conduct Instructional Analysis 6 
Analyze Learners and Contexts 7 
Write Performance Objectives 7 
Develop Assessment Instruments 7 
Develop Instructional Strategy 7 
Develop and Select Instructional Materials 7 
Design and Conduct the Formative Evaluation of Instruction 8  
Revise Instruction 8 
Design and Conduct Summative Evaluation 8 
 
Using the Systems Approach Model 9 
What Are the Basic Components of Systematically Designed Instruction? 9 
For Which Instructional Delivery System Is the Systems Approach Appropriate? 10 
Does the Use of the Systems Approach Imply that All Instruction Will Be 
Individualized 10 
Why Use the Systems Approach? 11 
Who Should Use the Systems Approach? 12 
 
References and Recommended Readings 13 
 
 
Chapter 2 
Assessing Needs to Identify Instructional Goal(s) 16 
 
Objectives 16 
 
Background 17 
 
Concepts 19 
Performance Analysis 19 
Clarifying Instructional Goals 22 
Learners, Context, and Tools 22 
Criteria for Establishing Instructional Goals 23  
 

Examples 25 
Leading Group Discussions 25 
Needs Assessment 25 
Clarifying the Instructional Goal 25  
Criteria for Establishing Instructional Goals 26  
Providing Customer Service 27 
 
Summary 30 
 
Practice 31  
 
Feedback 32 
 
References and Recommended Readings 34 
 
 
Chapter 3 
Conducting a Goal Analysis 36 
 
Objectives 36 
 
Background 37 
 
Concepts 38 
Verbal Information 39 
Intellectual Skills 39 
Psychomotor Skills 40 
Attitudes 40 
Goal Analysis Procedures 42 
Analysis of Substeps 45 
More suggestions for Identifying Steps within a Goal 46 
 
Examples 47 
Intellectual Skills Goals 48 
Psychomotor Skills Goals 49 
Attitudinal Goals 49 
Verbal Information Goals 51 
Typical First Approach to Goal Analysis 51  
 
Summary 53 
 
Practice 53 
 
Feedback 54 
 
References and Recommended Readings 56 
 
 
Chapter 4 
Identifying Subordinate Skills and Entry Behaviors 58 
 
Objectives 58 
 
Background 59 

 
Concepts 60 
Hierarchical Approach 60 
Cluster Analysis 65 
Subordinate Skills Analysis Techniques for Attitude Goals 66  
Combining Instructional Analysis Techniques 67  
Instructional Analysis Diagrams 68 
Entry Behaviors 70 
The Tentativeness of Entry Behaviors 73 
 
Examples 74 
Hierarchical Analysis of an Intellectual Skill 74 
Topic 74 
Instructional Goal 74 
Cluster Analysis for Verbal Information Subordinate Skills 76 
Topic 76 
Subordinate Skills 76 
Subordinate Skills Analysis of an Additional Goal That Requires Both Intellectual 
Skills and Verbal Information 79 
Topic 79 
Instructional Goal 79 
Analysis of a Psychomotor Skill 79 
Topic 79 
Instructional Goal 79 
Subordinate Skills Analysis for an Attitudinal Goal 82 
Topic 83 
Instructional Goal 83  
Identification of Entry Behaviors 84 
 
Summary 86 
 
Practice 87 
 
Feedback 90 
 
References and Recommended Readings 91 
 
 
Chapter 5 
Analyzing Learners and Contexts 94 
 
Objectives 94 
 
Background 95 
 
Concepts 96 
Learner Analysis 96 
Entry Behaviors 97 
Prior Knowledge of Topic Area 97 
Attitudes Toward Content and Potential Delivery System 97  
Academic Motivation (AR CS) 97 
Educational and Ability Levels 98 
General Learning Preferences 98 
Attitudes Toward Training Organization 98 
Group Characteristics 98 

Collecting Data for Learner Analysis 99 
Output 99 
Context Analysis of Performance Setting 99 
Managerial or Supervisor Support 99 
Physical Aspects of the Site 99 
Social Aspects of the Site 100 
Relevance of Skills to Workplace 100 
Collecting Data for Context Analysis in the Performance Setting 100  
Output 100 
Context Analysis of Learning Environment 100 
Compatibility of Site with Instructional Requirements 101  
Adaptability of Site to Simulate Workplace 101 
Adaptability for Delivery Approaches 101 
Learning-Site Constraints Affecting Design and Delivery 101  
Collecting Data for Context Analysis in the Learning Environment 102 
Output 102 
Public School Contexts 102 
Evaluation and Revision of the Instructional Analysis 103 
 
Examples 104 
Learner Analysis 104 
Performance Context Analysis 106  
Learning Context Analysis 108 
 
Summary 111 
 
Practice 113 
 
Feedback 115 
 
References and Recommended Readings 119 
 
 
Chapter 6 
Writing Performance Objectives 120 
 
Objectives 120 
 
Background 121 
 
Concepts 123 
Performance Objective 123 
Components of an Objective 124 
Derivation of Behaviors 125 
Derivation of Conditions 126 
Derivation of Criteria 128 
Process for Writing Objectives 129 
Evaluation of Objectives 130 
The Function of Objectives 131 
 
Examples 132 
Verbal Information and Intellectual Skills 132  
Verbal Information 134 
Intellectual Skills 134 
 
Psychomotor Skills 136 

Attitudes 136 
 
Summary 138 
 
Practice 139 
 
Feedback 142 
 
References and Recommended Readings 142 
 
 
Chapter 7 
Developing Assessment Instruments 144 
 
Objectives 144 
 
Background 145 
 
Concepts 146 
Four Types of Criterion-Referenced Tests and Their Uses 146 
Entry Behaviors Test 147 
Pretest 147 
Practice Tests 148 
Posttests 148 
Designing a Test 149 
Determining Mastery Levels 150 
Writing Test Items 151 
Goal-Centered Criteria 151 
Learner-Centered Criteria 152 
Context-Centered Criteria 153 
Assessment-Centered Criteria 153 
Setting Mastery Criteria 153 
Types of Items 154 
Sequencing Items 155 
Writing Directions 156 
Evaluating Tests and Test Items 156 
Developing Instruments to Measure Performances, Products, and Attitudes 157 
Writing Directions 158 
Developing the Instrument 158 
Identify, Paraphrase, and Sequence Elements 158  
Developing the Response Format 159 
Checklist 159 
Rating Scale 160 
Frequency Count 161 
Scoring Procedure 161 
Using Portfolio Assessments 162 
Evaluating Congruence in the Design Process 163 
 
Examples 165 
Test Items for Verbal Information and Intellectual Skills 165 
A Checklist for Evaluating Motor Skills 168 
Instrument for Evaluating Behaviors Related to Attitudes 170  
Materials for Evaluating the Design 171 
 
Summary 173 

 
Practice 174 
 
Feedback 178 
 
References and Recommended Readings 180 
 
 
Chapter 8 
Developing an Instructional Strategy 182 
 
Objectives 182 
 
Background 183 
 
Concepts 184 
 
Selection of Delivery System 185 
 
Instructional Strategies 186 
Content Sequence and Clustering 187 
Content Sequence 187 
Clustering Instruction 188 
Learning Components of Instructional Strategies 189  
 
Preinstructional Activities 190 
Motivating Learners 190 
Informing the Learner of the Objectives 192 
Informing the Learner of the Prerequisite Skills 192  
Content Presentation and Examples 193 
Learner Participation 193 
Assessment 194 
Follow-Through Activities 195 
Memory Skills 195 
Transfer of Learning 195 
Detailed Outline of Learning Components 196 
Learning Components for Learners of Different Maturity and Ability Levels 197 
Learning Components for Various Learning Outcomes 198  
Intellectual Skills 198 
Verbal Information 201 
Motor Skills 202 
Attitudes 203 
Student Groupings 205 
Selection of Media and Delivery systems 205 
Media selection for Domains of Learning 206 
Media Selection for Certain Task Requirements Found in Objectives 207 
Practical Considerations in Choosing Media and Delivery systems 207 
Alternative Views About Developing an Instructional Strategy 209  
Developing an Instructional strategy 209 
Evaluating an Instructional strategy 212 
 
Examples 214 
Sequence and Cluster Objectives 214 
Plan Preinstructional, Assessment, and Follow-Through Activities 215 
Plan Content Presentation and Student Participation 216 
Allocate Activities to Sessions 221 

Consolidate Media Selection and Confirm Of Select Delivery System 221 
 
Summary 224 
 
Practice 225 
 
Feedback 226 
 
References and Recommended Readings 238 
 
 
Chapter 9 
Developing Instructional Materials 240 
 
Objectives 240 
 
Background 241 
 
Concepts 242 
The Delivery System and Media Selections 242 
Availability of Existing Instructional Materials 242  
Production and Implementation Constraints 243 
Amount of Instructor Facilitation 243 
Components of an Instructional Package 245 
Instructional Materials 245 
Assessments 245 
Course Management Information 245 
Selecting Existing Instructional Materials 246 
Goal-Centered Criteria for Evaluating Materials 246  
Learner-Centered Criteria for Evaluating Materials 246  
Context-Centered Criteria for Evaluating Materials 246  
Learning-Centered Criteria for Evaluating Materials 247 
The Designer's Role in Material Development and Instructional Delivery 247 
When the Designer Is Also the Materials Developer and the Instructor 247 
When the Designer Is Not the Instructor 250 
Developing Instructional Materials for Formative Evaluation 251  
Rough Draft Materials 251 
Rapid Prototyping 252 
Materials Development Tools and Resources 253 
Beginning the Development Process 254 
Steps in the Development of Instruction 254 
 
Examples 255 
Preinstructional Activities 257 
Mediation of Preinstructional Activities 257 
Motivation Materials and Session Objectives 257 
Pretest 258 
Mediation of Pretest 259 
Content Presentation 260 
Mediation of Instruction 260 
Instruction 260 
Learner Participation 260 
Mediation of Learner Participation and Feedback 260  
Learner Participation Script 265 
Feedback 265 

 
Summary 269 
 
Practice 270 
 
Feedback 271 
 
References and Recommended Readings 281 
 
 
Chapter 10 
Designing and Conducting Formative Evaluations 282 
 
Objectives 282 
 
Background 283 
 
Concepts 284 
Role of Subject-Matter, Learning, and Learner Specialists in Formative Evaluation 285 
One-to-One Evaluation with Learners 286 
Criteria 286 
Selecting Learners 286 
Data Collection 287 
Procedures 288 
Assessments and Questionnaires 289 
Learning Time 290 
Data Interpretation 291 
Outcomes 291 
Small-Group Evaluation 291 
Criteria and Data 291 
Selecting Learners 292 
Procedures 292 
Assessments and Questionnaires 293 
Data Summary and Analysis 293 
Outcomes 293 
Field Trial 294 
Location of Evaluation 294 
Criteria and Data 294 
Selecting Learners 294 
Procedure for Conducting Field Trial 295 
Data Summary and Interpretation 295 
Outcomes 295 
Formative Evaluation in the Performance Context 295 
Criteria and Data 296 
Selecting Respondents 297 
Procedure 297 
Outcomes 297 
Collecting Data on Reactions to Instruction 297 
Formative Evaluation of Selected Materials 300 
Formative Evaluation of Instructor-Led Instruction 301 
Data Collection for Selected Materials and Instructor-Led Instruction 302 
Concerns Influencing Formative Evaluation 302 
Context Concerns 302 
Concerns about Learners 303 
Concerns about Formative Evaluation Outcomes 304 

Concerns with Implementing Formative Evaluation 304 
Problem Solving During Instructional Design 305 
 
Examples 305  
Formative Evaluation Activities 305 
One-to-One Evaluation 305 
Small-Group Evaluation 307 
Field Trial 309 
Formative Evaluation of Selected Materials and Instructor-Led Instruction 309 
Instruments for Assessing Learners' Attitudes about Instruction 310  
 
Summary 312 
 
Practice 314 
 
Feedback 315 
 
References and Recommended Readings 321 
 
 
Chapter 11 
Revising Instructional Materials 322 
 
Objectives 322 
 
Background 323 
 
Concepts 324 
Analyzing Data from One-to-One Trials 324 
Analyzing Data from Small-Group and Field Trials 325 
Group's Item-by-Objective Performance 326  
Learners' Item-by-Objective Performance 327 
Learners' Performance Across Tests 327 
Graphing Learners' Performances 329 
Other Types of Data 330 
Sequence for Examining Data 330 
Entry Behaviors 330 
Pretests and Posttests 330 
Instructional Strategy 331 
Learning Time 331 
Instructional Procedures 331 
Revision Process 332 
Revising Selected Materials and Instructor-Led Instruction 332 
 
Examples 333 
Summarizing Item-by-Objective Data Across Tests 334  
Summarizing and Analyzing Data Across Tests 336  
Summarizing Attitudinal Data 337 
Determining How to Revise Instruction 340 
 
Summary 342 
 
Practice 343 
 
Feedback 344 

 
References and Recommended Readings 346 
 
 
Chapter 12 
Designing and Conducting Summative Evaluations 348 
 
Objectives 348 
 
Background 349 
 
Concepts 350 
 
Expert Judgment Phase of Summative Evaluation 352 
Congruence Analysis 352 
Organization's Needs 352 
Resources 353 
Content Analysis 353 
Design Analysis 354 
Utility and Feasibility Analysis 354 
Current User Analysis 354 
 
Field-Trial Phase of Summative Evaluation 356 
Outcomes Analysis 356 
Planning 356 
Preparing 358 
Implementing/Collecting Data 358 
Summarizing and Analyzing Data 359 
Reporting Results 359 
 
Comparison of Formative and Summative Evaluation 359 
 
Examples 361 
Data Summary Form for the Congruence Analysis 361 
Checklist for Content Analysis:  
Evaluating the Completeness and Accuracy of Materials 361 
Checklists for Design Analysis:  
Evaluating the Learning and Instructional Strategies in Materials 362 
Motivation 364 
Types of Learning 365 
Instructional Strategies 367 
Form for Utility and Feasibility Analysis: Expert Judgment 368  
Form for Current Users' Analysis 368 
 
Summary 369 
 
Practice 371 
 
Feedback 371 
 
References and Recommended Readings 372 

Glossary of Terms 373 
 
Appendixes 377 
 
A  Description of Problem (Need), Purpose of Instruction, Target Group, 
and Delivery System 378 
 
B  Goal Analysis of the Instructional Goal on Story Writing 380 
 
C  Hierarchical Analysis of Declarative Sentence Portion of Story-Writing 
Goal with Entry Behavior Lines 381 
 
D  Design Evaluation Chart Containing Sub skills, Performance Objectives, 
and Parallel Test Items  382 
 
E  Instructional Strategy for Objective Sequence and Clusters, 
Preinstructional Activities, and Assessment Activities 385 
 
F  Instructional Strategy for the Content Presentation and Student 
Participation Components and the Lesson Time Allocation Based on the 
Strategy 387 
 
G  Session 1: Motivational Materials, Unit Objectives, and Assessment of 
Entry Behaviors 390 
 
H  Session 2: Pretest Story and Rubric to Evaluate Stories 392 
 
I  Session 3: Pretest and Instruction in Subordinate Skills 5.6 through 5.11 
394 
 
J  Group's and Individuals' Achievement of Objectives and Attitudes About 
Instruction 398 
 
K  Materials Revision Analysis Form 406 
 
Index 409 

Chapter 1 
 
Introduction to instructional 
design 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Conduct 
Instructional 
Analysis 
Write  
Performance
Objectives 
Develop 
Assessment 
Instruments 
Analyze 
Learners 
and 
Contexts 
Develop 
Instructional 
Strategy 
Develop and 
Select 
Instructional 
Materials 
Develop and 
Construct 
Formative 
Evaluation of
Instruction
Design and 
Conduct 
Summative 
Evaluation 
Revise 
Instruction 
Assess 
Needs to 
Identify 
Goal(s) 
 
 
The Dick and the Carey Systems Approach Model for  
Designing Instruction 
 
The instructional process, or teaching, has traditionally involved instructors, learners, and textbooks. 
The content to be learned was contained in the text, and it was the instructor's responsibility to 
"teach" that content to the learners. Teaching could be interpreted as getting content from the text into 
the heads of learners in such a way that they could retrieve the information for a test. With this model, 
the way to improve instruction is to improve the instructor (i.e., to require the instructor to acquire 
more knowledge and to learn more methods for conveying it to learners). 
 
A more contemporary view of instruction is that it is a systematic process in which every 
component (i.e., teacher, learners, materials, and learning environment) is crucial to successful 
learning. This perspective is usually referred to as the systems point of view, and advocates of this 
position typically use the systems approach to design instruction. 
 
 

Let's consider what is meant by a system, and then consider the systems approach. The term system 
has become very popular as more and more of what we do is interrelated with what other people do. 
A system is technically a set of interrelated parts, all of which work together toward a defined goal. 
The parts of the system depend on each other for input and output, and the entire system uses 
feedback to determine if its desired goal has been reached. If it has not, then the system is modified 
until it does reach the goal. The most easily understood systems are those we create rather than those 
that occur naturally. For example, you probably have a heating or cooling system in your home that 
consists of various components that work together to produce warmth or coolness. The thermostat is 
the feedback mechanism through which the thermometer constantly checks the temperature and 
signals the system when more heat or cold is needed. When the desired temperature is reached, the 
system shuts itself off. 
 
How is this related to instruction? First, the instructional process itself can be viewed as a 
system. The purpose of the system is to bring about learning. The components of the system are the 
learners, the instructor, the instructional materials, and the learning environment. These components 
interact in order to achieve the goal. For example, the instructor reviews sample problems in the 
textbook or manual with the learners in a quiet classroom. To determine whether learning is taking 
place, a test is administered. This is the instructional system thermostat. If learner performance is not 
satisfactory, then changes must be enacted to make the system more effective and to bring about the 
desired learning outcomes. 
 
The result of using the systems view of instruction is to see the important role of all the 
components in the process. They must all interact effectively, just as the parts in a heating or cooling 
system must interact effectively in order to bring about the desired outcomes. There is not an 
overemphasis of any one component in the system, but a determination of the exact contribution of 
each one to the desired outcome. And it is clear that there must be both an assessment of the 
effectiveness of the system in bringing about learning and a mechanism to make changes if learning 
fails to occur. 
 
Thus far, our discussion of the instructional process has focused on the interactive 
component of the process-namely, the time instructors and learners come together with the hope that 
learning will occur. But what about the preparation for the instructional process? How does the 
instructor decide what to do, and when? It is not surprising that someone with a systems view sees 
the preparation, implementation, evaluation, and revision of instruction as one integrated process. In 
the broadest systems sense, a variety of sources provide input to the preparation of the instruction. 
The output is some product or combination of products and procedures that are implemented. The 
results are used to determine whether the system should be changed, and, if so, how. 
 
The purpose of this book is to describe a systems approach model for the design, 
development, implementation, and evaluation of instruction. This is not a physical system such as a 
furnace or air conditioner or heat pump (which will do both) but a procedural system. We will 
describe a series of steps, all of which will receive input from the preceding steps and will provide 
output for the next steps. All of the components work together in order for the user to produce 
effective instruction. The model includes an evaluation component that will help determine what, if 
anything, went wrong and how it can be improved. 
While our model will be referred to as a systems approach model, we must emphasize that there is no 
single systems approach model for designing instruction. A number of models bear the label systems 
approach, and all of them share most of the same basic components. The systems approach model 
presented in this book is less complex than some but includes the major components included in 
other models. Collectively, these design models and the processes they represent are referred to as 
Instructional Systems Development (ISD). 
 
Typically the major phases of ISD are analysis, design, development, implementation, and 
evaluation. Our particular model does not emphasize the first phase, analysis. Before instruction is 
created, it is necessary to deter- mine the need for that instruction in terms of what problem within 
the organization will be solved through the use of new skills, or what opportunity can be seized 
because of new skills in the organization. This step is critically important to the success of the design 
process; however, there are excellent books that describe the performance analysis and needs 

assessment processes (see Kaufman, 1991, and Rossett, 1999). We will give only a brief description 
in Chapter 2 of the analysis process in order to create a context for the remainder of the model. 
 
Note that the term instructional design is used as an umbrella term that includes all the 
phases of the ISD process. The term design is included in the general name of the process and is also 
the name for one of the major sub- processes. When we use the term instructional design, we will be 
referring to the entire ISD process. We will not belabor the issue of terminology further at this point. 
It will all become clear as you begin to use the instructional design process. 
 
Instructional design models are based, in part, on many years of research on the learning 
process. Each component of the model is based on theory and, in most instances, on research that 
demonstrates the effectiveness of that component. The model brings together in one coherent whole 
many of the concepts that you may have already encountered in a variety of educational situations. 
For example, you undoubtedly have heard of performance objectives and may have already 
developed some yourself. Such terms as criterion-referenced testing and instructional strategy may 
also be familiar .The model will show how these terms, and the processes associated with them, are 
interrelated and how these procedures can be used to produce effective instruction. 
 
The instructional strategy component of our model describes how the designer uses the 
information from the analysis of what is to be taught to formulate a plan for presenting instruction to 
learners. Our original approach to this component of the model was heavily influenced by the work of 
Robert Gagné as found in his book The Conditions of Learning, first published in 1965. Gagné's early 
work in the 1940s and 1950s was based on assumptions from behavioral psychology, where 
instruction is the reinforcement of appropriate learner responses to stimulus situations set up by the 
teacher. If students have learned, then it is more likely that they will exhibit a desired behavior in a 
given situation. Gagné's first edition of The Conditions of Learning, however, incorporated cognitive 
information-processing views of learning. In this view most behavior is assumed to be very complex 
and controlled primarily by a person's internal mental processes rather than external stimuli and 
reinforcements. Instruction is seen as organizing and providing sets of information and activities that 
guide, support, and augment students' internal mental processes. Learning has occurred when students 
have incorporated new information into their memories that enables them to master new knowledge 
and skills. Gagné further develops cognitive views of learning and instruction in later editions of The 
Conditions of Learning (1970, 1977, 1984). 
 
Constructivism is a relatively recent branch of cognitive psychology that has had a major 
impact on the thinking of many instructional designers. Constructivist thinking varies broadly on 
many issues, but the central point is that learning is always a unique product "constructed" as each 
individual learner combines new information with existing knowledge and experiences. Individuals 
have learned when they have constructed new interpretations of the social, cultural, physical, and 
intellectual environments in which they live. Because learning in the constructivist view is so 
entwined with one's experiences, a primary role of the teacher is creating appropriate learning 
environments, sometimes called problem scenarios, in which students' learning experiences are 
authentic representations of real practices in applied settings. 
 
Throughout this text, readers will find elements of behaviorist, cognitivist, and constructivist 
views adopted and adapted as appropriate for the varieties of learners, learning outcomes, learning 
contexts, and performance contexts that are discussed. The Dick and Carey Model incorporates an 
eclectic set of tools drawn from each of these three major theoretical positions of the past fifty years. 
 
One additional comment may help clarify distinctions regarding the learning theories that 
underlie this instructional design model. As you read through the following chapters you will find the 
term behavior frequently used in all of its forms in a variety of different contexts. On finding repeated 
uses of the term, one might infer that the predominant theoretical foundation of the text is 
behaviorism. This would be a wrong assumption that arises from a confusion between the learning 
theory called behaviorism and the tools used by behaviorist psychologists and all other psychologists 
to study learning. The behaviorist views learning as a change in the probability of a response, but can 
only determine that a change in probability (i.e., learning) has occurred by observing the behavior. 
The tool used by the behaviorist (observation of behavior) is shared by all psychologists who study 
learning. Thus, the term behavior will be used frequently in this text, but it should not be concluded 

that we recommend either the classical conditioning models of early behaviorists or the operant 
conditioning models of later behaviorists as the primary theoretical foundations for designing and 
implementing instruction. 
 
The model, as it is presented here, is based not only on theory and research but also on a 
considerable amount of practical experience in its application. We suggest that the novice 
instructional designer use the model principally in the sequence and manner presented in this chapter 
because students who have done so have been successful. On the other hand, we acknowledge that in 
particular circumstances and with increased design experience, you might need to change the model, 
or to perform the steps out of sequence. Also, we expect that more research and experience will help 
amplify the procedures associated with each component of the model. 
 
In the section that follows, we will present the general systems approach model in much the 
same way as a cookbook recipe-you do this and then you do that. When you begin to use a recipe in 
your own kitchen, however, it takes on greater meaning, just as the model will when you begin to 
develop your own instruction: You select a topic for which instruction is needed, you develop your 
own instructional resources, you select your own set of learners, and 80 on. Your perspective on the 
model will probably change greatly. In essence, your use of your own kitchen, your own ingredients, 
and your own personal touch will result in a unique product. 
 
The model that will be described in detail in succeeding chapters is presented on pages 2 and 
3. The model includes ten interconnected boxes and a major line that shows feedback from the next-
to-last box to the earlier boxes. The boxes refer to sets of procedures and techniques employed by the 
instructional designer to design, develop, evaluate, and revise instruction. The steps will be briefly 
described in sequence below and in much greater detail in subsequent chapters. 
 
Components of the Systems Approach Model 
 
ASSESS NEEDS TO lDENTIFY GOAL(S) 
The first step in the model is to determine what it is that you want learners to be able to do when they 
have completed your instruction. The instructional goal may be derived from a list of goals, from a 
needs assessment, from practical experience with learning difficulties of students, from the analysis of 
people who are doing a job, or from some other requirement for new instruction. 
 
CONDUCT INSTRUCTIONAL ANALYSIS 
After you have identified the instructional goal, you will determine step-by- step what people are 
doing when they perform that goal. The final step in the instructional analysis process is to determine 
what skills, knowledge, and attitudes, known as entry behaviors, are required of learners to be able to 
begin the instruction. A diagram will be produced that depicts the relationships among all of the skills 
that have been identified. 
 
ANALYZE LEARNERS AND CONTEXTS 
In addition to analyzing the instructional goal, there is a parallel analysis of the learners, the context 
in which they will learn the skills, and the context in which they will use them. Learners' current 
skills, preferences, and attitudes are determined along with the characteristics of the instructional 
setting and the setting in which the skills will eventually be used. This crucial information shapes a 
number of the succeeding steps in the model, especially the instructional strategy. 
 
WRITE PERFORMANCE OBJECTIVES 
Based on the instructional analysis and the statement of entry behaviors, you will write specific 
statements of what the learners will be able to do when they complete the instruction. These 
statements, which are derived from the skills identified in the instructional analysis, will identify the 
skills to be learned, the conditions under which the skills must be performed, and the criteria for 
successful performance. 

 
DEVELOP ASSESSMENT INSTRUMENTS 
Based on the objectives you have written, develop assessments that are parallel to and measure the 
learners' ability to perform what you described in the objectives. Major emphasis is placed on relating 
the kind of behavior described in the objectives to what the assessment requires. 
 
DEVELOP INSTRUCTIONAL STRATEGY 
Based on information from the five preceding steps, identify the strategy that you will use in your 
instruction to achieve the terminal objective. The strategy will include sections on pre-instructional 
activities, presentation of information, practice and feedback, testing, and follow-through activities. 
The strategy will be based on current theories of learning and results of learning research, the 
characteristics of the medium that will be used to deliver the instruction, content to be taught, and the 
characteristics of the learners who will receive the instruction. These features are used to develop or 
select materials or to develop a strategy for interactive classroom instruction. 
 
DEVELOP AND SELECT INSTRUCTIONAL MATERIALS 
In this step you will use your instructional strategy to produce the instruction. This typically includes 
a learner's manual, instructional materials, and tests. (When we use the term instructional materials 
we are including all forms of instruction such as instructor's guides, student modules, overhead 
transparencies, videotapes, computer-based multimedia formats, and web pages for distance learning. 
We intend the term materials to have this broad connotation.) The decision to develop original 
materials will depend on the type of learning to be taught, the availability of existing relevant 
materials, and developmental resources available to you. Criteria for selecting from among existing 
materials are provided. 
 
DESIGN AND CONDUCT TBE FORMATIVE EVALUATION OF INSTRUCTION 
Following the completion of a draft of the instruction, a series of evaluations is conducted to collect 
data that are used to identify how to improve the instruction. The three types of formative evaluation 
are referred to as one-to- one evaluation, small-group evaluation, and field evaluation. Each type of 
evaluation provides the designer with a different type of information that can be used to improve the 
instruction. Similar techniques can be applied to the formative evaluation of existing materials or 
classroom instruction. 
 
REVISE INSTRUCTION 
The final step (and the first step in a repeat cycle) is revising the instruction. Data from the formative 
evaluation are summarized and interpreted to attempt to identify difficulties experienced by learners 
in achieving the objectives and relate these difficulties to specific deficiencies in the instruction. The 
line in the figure on pages 2 and 3 labeled "Revise Instruction" indicates that the data from a 
formative evaluation are not simply used to revise the instruction itself, but are used to reexamine the 
validity of the instructional analysis and the assumptions about the entry behaviors and characteristics 
of learners. It is necessary to reexamine statements of performance objectives and test items in light 
of collected data. The instructional strategy is reviewed and finally all this is incorporated into 
revisions of the instruction to make it a more effective instructional tool. 
 
DESIGN AND CONDUCT SUMMATIVE EVALUATION 
Although summative evaluation is the culminating evaluation of the effectiveness of instruction, it 
generally is not a part of the design process. It is an evaluation of the absolute and/ or relative value or 
worth of the instruction and occurs only after the instruction has been formatively evaluated and 
sufficiently revised to meet the standards of the designer. Since the summative evaluation usually 
does not involve the designer of the instruction but instead involves an independent evaluator, ibis 
component is not considered an integral part of the instructional design process per se. 
 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Conduct 
Performance
Analysis 
Can the need be 
solved through 
instruction? 
Conduct Job 
Analysis 
Apply Dick & 
Carey ID 
Model 
Apply Dick & 
Carey ID 
Model 
Goal 2 
Goal n 
Goal 1 
Apply Dick & 
Carey ID 
Model 
Conduct 
Summative 
Evaluation 
Conduct 
Needs 
Assessment 
Choose 
Noninstructional 
Solutions 
 
Figure 1.1 
The Role of the Dick and Carey Model in the Broader Curriculum   
 
 
Development Process 
 
The nine basic steps represent the procedures that one employs when the systems approach is used to 
design instruction. This set of procedures is referred to as a systems approach because it is made up of 
interacting components, each having its own input and output, which together produce pre- 
determined products. Data are also collected about the system's effectiveness so that the final product 
can be modified until it reaches the desired quality level. When instructional materials are being 
developed, data are collected and the materials are revised in light of these data to make them as 
effective and efficient as possible. 
 
Before concluding our discussion of the systems approach model, it should be made clear 
that, as it stands, this is not a curriculum design model. In order to design a curriculum many more 
steps would be required before identifying the instructional goals. Some of these techniques are 
known as needs assessment and job analysis. One should use the model in curriculum development 
projects after the instructional goals have been derived. Figure 1.1 illustrates how the Dick and Carey 
Model would fit into a broader curriculum development process. 
 
 
Using the Systems Approach Model 
 
Now that you have read about this model, you should consider several very important questions about 
its use. These are discussed in the sections that follow. 
 
WHAT ARE THE BASIC COMPONENTS OF SYSTEMATICALLY DESIGNED 
INSTRUCTION? 
When the systems approach is used, some form of instructional materials is almost always created. 
These materials were initially referred to as programmed instruction. As the format changed, they 
became learning activity packages (LAPs) and modules. We will simply refer to instruction. A 
module is usually a self-instructional printed unit of instruction that has an integrated theme, provides 
students with information needed to acquire and assess specified knowledge and skills, and serves as 
one component of a total curriculum. While printed modules are still quite popular as a format for 

instruction, more and more designers are choosing to use computers, and specifically the Internet, as 
the mechanism for delivering selected modules, a complete unit of instruction, or a total curriculum. 
 
Systematically designed instruction requires learners to interact actively with the instructional 
materials rather than simply allowing them to read the materials passively. The learners are asked to 
perform various types of learning tasks and receive feedback on that performance. Some type of 
testing strategy informs the learners whether they achieved mastery of the content and what they 
should do if they did not. 
 
Based on the description of prior paragraphs, how would you recognize a module if you saw 
one? In its most simple form, a module might include a statement to students that says what it is they 
are about to learn and how they will be tested. It would provide printed instructional materials as well 
as some practice exercises. A self-test that might be used prior to taking a terminal test could also be 
included. 
 
A more complex module might contain all of the items listed above, but might also 
incorporate a number of alternative sets of materials from which the learner could choose the one 
most appropriate. Alternative media forms such as a web site or videotapes could also be included. In 
addition, the learner might go to a laboratory to conduct an experiment or go outside the learning 
environment to gather information. 
 
Keep in mind two important points. First, it is not possible to examine instructional materials 
and decide whether they contain all the components of systematically designed instruction. Many 
factors enter into the design decisions that determine what is and is not included. Second, you cannot 
determine by inspection whether instruction has been systematically designed. The systems approach 
is a process that is followed by designers, but it is not necessarily apparent by reviewing instructional 
materials. For example, simply inserting a set of objectives at the beginning of each chapter in a 
textbook does not mean that the textbook has been systematically designed! 
 
FOR WHICH INSTRUCTIONAL DELIVERY SYSTEM IS THE SYSTEMS 
APPROACH APPROPRIATE? 
The systems approach to the design of instruction includes the planning, development, 
implementation, and evaluation of instruction. As a part of this process, the delivery method of the 
instruction must be chosen. In some instances, it is most appropriate to have an instructor deliver the 
instruction, while in other situations, a variety of media may be employed. Most recently it seems that 
every new instructional effort tends to include a computer. In every instance, the systems approach is 
an invaluable tool for identifying what is to be taught, determining how it win be taught, and 
evaluating the instruction to find out whether it is effective. 
 
The procedure described in this text for developing an instructional strategy is a generic one. 
It is applicable to the development of print instruction that is still favored in many instances for 
portability and production cost. The procedure can be easily used, however, to fit the requirements of 
any selected medium of instruction. Materials developers in video or multimedia, for example, could 
use the instructional strategy statements to create storyboards, screen displays, or flow charts for 
hyper linking interactive sequences. The use of the systems approach prevents the designer from 
trying to create instruction for a medium prior to a complete analysis of what is to be taught and how. 
Most research suggests that it is the analysis process and the instructional strategies, rather than the 
delivery mode, that determine the success of the instruction. The systems approach is a generic 
planning process that ensures that instructional products developed for any delivery system are 
responsive to the needs of learners and effective in achieving the desired learning outcomes. 
 
DOES THE USE OF THE SYSTEMS APPROACH IMPLY THAT ALL 
INSTRUCTION WILL BE INDIVIDUALIZED? 
From our discussion of the development of printed modules and computer- based instruction, the 
reader might assume that systematically designed instruction is the same as individualized instruction; 
it is not. Let's assume, for the sake of discussion, that individualized instruction permits learners to 
progress at their own rate. (This is considered the minimal definition of individualized instruction!) A 

well-designed print module or computer-based lesson could certainly be used in this manner. So the 
systems approach can be used to design individualized instruction. However, it can also be used to 
design group-based instruction if we may use this term in contrast with individualized instruction. 
The systems approach can be used, as already noted, to develop all types of instructor-led and 
interactive group activities. In fact, it is often the case that these are precisely the conditions that are 
most effective and efficient for bringing about the desired learning outcomes. 
 
The reader should be careful to distinguish between the process of designing instruction and 
the delivery of that instruction. The systems approach is basically a design process, whereas 
instructors, modules, computers, and televisions are delivery mechanisms. These delivery 
mechanisms can be used with one or many learners at the same time. A major part of the design 
process is to determine how the instruction can be delivered most effectively. 
 
The beneficiary of the application of the systems approach to the design of instruction is the 
individual learner. Careful attention is paid to determining what must be learned and what learners 
must already know in order to begin the instruction. The instruction is focused on the skills to be 
learned and is presented under the best conditions for learning. The learner is evaluated fairly with 
instruments that measure the skills and knowledge described in the objectives, and the results are used 
to revise the instruction so that it will be even more effective with succeeding learners. Following this 
process causes the designer to focus on the needs and skills of the learners and results in the creation 
of effective instruction. 
 
WHY USE THE SYSTEMS APPROACH? 
Few formal research studies address the question of the overall total effectiveness of the systems 
approach to designing instruction. Although much research has been done on various components of 
the model, rigorous studies that involve the total model are extremely rare because they are 80 
difficult to conduct. The few studies that have been published tend to provide strong support for the 
approach. The primary support for the model, however, comes from designers who have used the 
process and have documented their success with learners. 
 
It appears that there are a number of reasons that systematic approaches to instructional 
design are effective. The first is the focus, at the outset, on what learners are to know or be able to do 
when the instruction is concluded. Without this precise statement, subsequent planning and 
implementation steps can become unclear and ineffective. 
 
A second reason for the success of the systems approach is the careful linkage between each 
component, especially the relationship between the instructional strategy and the desired learning 
outcomes. Instruction is specifically targeted on the skills and knowledge to be taught and supplies 
the appropriate conditions for the learning of these outcomes. Stated another way, instruction does not 
consist of a range of activities only some of which may be related to what is to be learned. 
 
The third and perhaps most important reason for the success of the systems approach is that it 
is an empirical and replicable process. Instruction is designed not for one delivery, but for use on as 
many occasions as possible with as many learners as possible. Because it is reusable, it is worth the 
time and effort to evaluate and revise it. In the process of systematically designing instruction, data 
are collected to determine what part of the instruction is not working, and it is revised until it does 
work. 
 
Because of these characteristics, the systems approach is valuable to instructors who are 
interested in successfully teaching basic and higher level competencies to learners. The competency-
based approach has been widely adopted among educators; however, the most numerous applications 
of the systems approach may be found in industry and in military services. In these environments 
there is a premium on both efficiency of instruction and quality of student performance. The payoffs 
in both situations are quite obvious. 
 
WHO SHOULD USE THE SYSTEMS APPROACH? 
As you study the instructional design model and, we hope, use it to design some instruction, you will 
find that it takes both time and effort. You will probably find yourself saying, "I could never use this 
process to prepare all my instruction," and you would probably be correct. The individual instructor 

who has day-to-day instructional responsibilities can use the process to develop only small amounts 
of written or mediated instruction at any given time. The process can also be used effectively and 
efficiently to select from among existing materials and to design instruction that is not materials 
based. 
 
We have found that almost every instructor who has studied the process has come away with 
two reactions. The first is that they will certainly begin immediately to use some of the components in 
the model, if not all of them. The second reaction is that their approach to instruction will never be the 
same because of the insights they have gained from using the process. (The reader may be somewhat 
skeptical at this point; be sure to consider your own reactions after you have used this approach.) 
 
A second group of users of the ISD approach is growing quite rapidly. They are typically 
referred to as instructional designers, since they are trained to use a systematic approach to designing 
new instructional systems or improving already existing systems. Their full-time job is to create 
replicable instructional programs that are effective with a particular learner population. 
 
In contrast to the instructor who may be working alone, the instructional designer often works 
with a team of specialists to develop the instruction. The team would typically include a content 
specialist, a media production specialist, an evaluation specialist, and a manager. (When the instructor 
works alone, he or she usually must fill all of these roles.) The team approach draws on the expertise 
of specialists to produce a product that none could produce alone. In these settings there is a premium 
placed on interpersonal skills because seemingly everyone has ideas on how best to do what needs to 
be done. 
 
This book has been written for both the instructor who would like to know more about the 
systems approach to instructional design and the beginning instructional designer who may pursue a 
career in this field. The book is also intended for the public school teacher, the university professor, 
the industrial trainer, and the military instructor. We are convinced that the model and procedures are 
equally applicable in both school and non school settings. 
 
In our examples of various aspects of the application of the systematic design process, we 
have included instruction that is intended for all age groups, from young children to mature adults. 
We will use the terms teacher, instructor, and designer interchangeably throughout the book because 
we truly believe they are interchangeable. 
As you read through the chapters that follow, you will find an instructional design example on 
training Neighborhood Crime Watch leaders. The example is carried through each step of the design 
model. You should also note that Appendices A through K contain an instructional design example 
for a school subject that is carried through each step of the model (using a variety of sentence types in 
writing paragraphs). 
 

References and Recommended Readings 
 
At the end of each chapter, several carefully 
selected references are listed. The books and 
articles supplement the description in the chapter 
or focus in more detail on an important concept 
that has been presented. 
The references listed for this first chapter are 
somewhat different. These are books in the field 
of instructional design or ones that have direct 
implications for the practice of instructional 
design. Many of the topics in this book also 
appear in these references. The books vary in 
depth and breadth of coverage of topics, but they 
should all help to expand your knowledge and 
understanding of the instructional design field. 
 
Anglin, G. J. (Ed.). (1991). Instructional technology: 
Present, past, and future. Englewood, CO: Libraries 
Unlimited. Wide range of informative chapters on the 
entire field of instructional technology. 
Banathy, Bela H. (1968). Instructional systems. Palo Alto, 
CA: Fearon Publishers. 
Banathy, Bela H. (1992). Comprehensive systems design 
in education. Educational Technology, 32(1), 33-35. 
Briggs, L. J., Gustafson, K. L., & Tillman, M. H. (Eds.). 
(1991). 
Instructional 
design: 
Principles 
and 
applications. 
Englewood 
Cliffs, 
NJ: 
Educational 
Technology Publications. An update of an older classic. 
Many of our chapters parallel chapters in this book. 
Dills, C. R., & Romiszowski, A. J. (1997). Instructional 
development 
paradigms. 
Englewood 
Cliffs, 
NJ: 
Educational Technology Publications. Presents various 
models and approaches to instructional design. 
Driscoll, Marcy P. (1994). Psychology of learning for 
instruction. Boston: Allyn & Bacon. Contemporary 
approaches to learning that focus on instruction. 
Duffy, T. M., & Jonassen, D. H. (Eds.). (1992). 
Constructivism and the technology of instruction. 
Hillsdale, 
NJ: 
Lawrence 
Earlbaum 
Associates. 
Comprehensive review of varying perspectives on 
constructivism. 
Ertmer, P. A., & Newby, T. J. (1993). Behaviorism, 
cognitivism, constructivism: Comparing critical features 
from an instructional design perspective. Performance 
Improvement Quarterly, (6)4,50-72. Useful comparisons 
of 
three 
theoretical 
bases 
with 
guidelines 
for 
instructional designers. 
Ertmer, P. A., & Quinn, J. (1999). The ID casebook: 
Case studies in instructional design. Upper Saddle 
River, NJ: Prentice Hall. Wide array of examples of the 
application of instructional design processes to real 
world problems. 
Fleming, Malcolm L., & Levie, W. Howard (1993). 
Instructional message design. (2nd ed.). Englewood 
Cliffs, NJ : Educational Technology Publications. 
Gagné, Robert M. (1985). The conditions of learning (4th 
ed.). New York: Holt, Rinehart and Winston. 
Gagné, Robert M. (Ed.). (1987). Instructional technology: 
Foundations. 
Hillsdale, 
NJ: 
Lawrence 
Erlbaum 
Associates. 
Gagné, Robert M., Briggs, Leslie J., & Wager, Walter 
W. (1992). Principles of instructional design (4th ed.). 
New York: Holt, Rinehart and Winston. 
Gagné, Robert M., & Medsker, Karen L. (1996). The 
conditions of learning: training applications. Fort 
Worth, TX: Harcourt Brace College Publishers. Same 
model as Gagné's original text by this name, but with the 
addition of examples from business and industry. 
Gredler, Margaret E. (1997). Learning and instruction: 
Theory into practice (3rd ed.). Upper Saddle River, NJ: 
Prentice-Hall. A survey of learning theories that 
includes behaviorist, cognitivist, and constructivist 
views with applications for instruction. 
Hannum, W., & Hansen, C. (1989). Instructional systems 
development in large organizations. Englewood Cliffs, 
NJ: 
Educational 
Technology 
Publications. 
An 
examination of the instructional design process as it is 
used with large projects. 
Kaufman, R. (1991). Strategic planning plus: An 
organizational guide. Indianapolis, IN: Circle City 
Press. 
Kemp, J. E., Morrison, G. R., & Ross, S. M. (1998). 
Designing effective instruction (2nd ed.). New York: 
Merrill Publishing. A revision of an older book, this 
edition covers many current instructional design con- 
cepts. 
Knirk, Frederick G., & Gustafson, Kent L. (1986). 
Instructional technology: A systematic approach to 
education. New York: Holt, Rinehart and Winston. 
Mager, Robert F. (1988). Making instruction work. 
Belmont, CA: Lake Publishing Co. 
Mager, Robert F. (1992). What every manager should 
know about training. Belmont, CA: Lake Publishing Co. 
Merrill, M. D., Drake, L., Lacy, M. J., & Pratt, J. 
(1996). Reclaiming instructional design. Educational 
Technology, 36(5),5-7. 
Reiser, R. A., & Dick, W. (1996). Instructional planning: 
A guide for teachers (2nd ed.). Boston, MA: Allyn and 
Bacon. A short book about the instructional design 
process for teachers and trainers. 
Richey, R. (1992). Designing instruction for the adult 
learner. London: Kogan Page Limited. A theory of 
instruction based on an extensive review of the literature 
and empirical data from training studies. 
 

Romiszowski, A. J. (1981). Designing instructional 
systems. London: Kogan Page. 
Romiszowski, A. J. (1984). Producing instructional 
systems. London: Kogan Page. 
Rossett, A. (1999). First things fast. San Francisco, CA: 
Jossey-Bass Pfeiffer. Performance analysis is contrasted 
with training needs assessment. 
Rothwell, W. J., & Kazanas, H. C. (1997). Mastering the 
instructional design process: A systematic approach. 
(2nd ed.). San Francisco, CA: Jossey-Bass Publishers. A 
general text on the instructional design process. 
Saettler, Paul (1990). The evolution of American 
educational technology. Englewood, CO: Libraries 
Unlimited. Very complete historical description of the 
development of the audiovisual field and the growth of 
instructional design. 
Seels, Barbara, (Ed.). (1995). Instructional design 
fundamentals: A reconsideration. Englewood Cliffs, NJ: 
 
Educational Technology Publications. Perspectives on 
instructional design from theory, and implications for the 
design process. 
Seels, B., & Glasgow, z. (1990). Exercises in instructional 
design. Columbus, OH: Merrill. Fine set of practice 
activities for many of the skills taught in this text. 
Seels, B., & Richey, R. (1994). Instructional technology: 
l1Ie definition and domains of the field. Washington, DC: 
Association for Educational Communications and 
Technology. Current thinking about the distinctive 
features of instructional technology that includes 
instructiortal design. 
Smith, P. L., & Ragan, T. J. (1999). Instructional design 
(2nd ed.). New York: Wiley. Excellent chapters on 
instructional strategies for various learning outcomes. 
 
 
